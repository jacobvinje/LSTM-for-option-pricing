{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2MNO3kPTnkd"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oOQkqhqFTnkg"
      },
      "outputs": [],
      "source": [
        "# Weights and Biases\n",
        "!pip install -q wandb\n",
        "# Tensorflow\n",
        "!pip install -q tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bfwvf6vGTnki"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, LSTM, Concatenate, Dense, BatchNormalization, LeakyReLU\n",
        "from keras.activations import tanh\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from tensorflow import square, reduce_mean\n",
        "from tensorflow.keras.losses import MSE\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.math import multiply\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
        "from math import log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fduF6iTTnkj",
        "outputId": "d2445b67-74af-4c25-8416-40c9b15f4590"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinje\u001b[0m (\u001b[33mavogadro\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# If running in colab, insert your wandb key here\n",
        "\n",
        "#import config\n",
        "#Erlend\n",
        "#wandb.login(key=config.erlend_key)\n",
        "# Hjalmar\n",
        "wandb.login(key=\"b47bcf387a0571c5520c58a13be35cda8ada0a99\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJGDiGMLTnkl"
      },
      "source": [
        "# Load, split and normalize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1j3mQWTnkl"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "OKcl8WWJTnkl",
        "outputId": "87203c58-e9b7-4095-9930-de837a785092"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 24 20:24:11 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Unnamed: 0.1  Unnamed: 0  Quote_date     Price  Underlying_last  \\\n",
              "0             6701729     6701729  2020-01-02  1755.645          3258.14   \n",
              "1             6701730     6701730  2020-01-02  1655.955          3258.14   \n",
              "2             6701731     6701731  2020-01-02  1556.195          3258.14   \n",
              "3             6701732     6701732  2020-01-02  1456.210          3258.14   \n",
              "4             6701733     6701733  2020-01-02  1406.200          3258.14   \n",
              "...               ...         ...         ...       ...              ...   \n",
              "5185540      12459146    12459146  2022-12-30   415.150          3839.81   \n",
              "5185541      12459147    12459147  2022-12-30   375.050          3839.81   \n",
              "5185542      12459148    12459148  2022-12-30   337.350          3839.81   \n",
              "5185543      12459149    12459149  2022-12-30   302.650          3839.81   \n",
              "5185544      12459150    12459150  2022-12-30   270.450          3839.81   \n",
              "\n",
              "         Strike   TTM     R  Moneyness  \n",
              "0        1500.0     1  1.53   2.172093  \n",
              "1        1600.0     1  1.53   2.036338  \n",
              "2        1700.0     1  1.53   1.916553  \n",
              "3        1800.0     1  1.53   1.810078  \n",
              "4        1850.0     1  1.53   1.761157  \n",
              "...         ...   ...   ...        ...  \n",
              "5185540  4500.0  1085  4.22   0.853291  \n",
              "5185541  4600.0  1085  4.22   0.834741  \n",
              "5185542  4700.0  1085  4.22   0.816981  \n",
              "5185543  4800.0  1085  4.22   0.799960  \n",
              "5185544  4900.0  1085  4.22   0.783635  \n",
              "\n",
              "[5185545 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3621f79b-35b6-4d51-a138-d7d9dc272b90\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Quote_date</th>\n",
              "      <th>Price</th>\n",
              "      <th>Underlying_last</th>\n",
              "      <th>Strike</th>\n",
              "      <th>TTM</th>\n",
              "      <th>R</th>\n",
              "      <th>Moneyness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6701729</td>\n",
              "      <td>6701729</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>1755.645</td>\n",
              "      <td>3258.14</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.172093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6701730</td>\n",
              "      <td>6701730</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>1655.955</td>\n",
              "      <td>3258.14</td>\n",
              "      <td>1600.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.036338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6701731</td>\n",
              "      <td>6701731</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>1556.195</td>\n",
              "      <td>3258.14</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.53</td>\n",
              "      <td>1.916553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6701732</td>\n",
              "      <td>6701732</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>1456.210</td>\n",
              "      <td>3258.14</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.53</td>\n",
              "      <td>1.810078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6701733</td>\n",
              "      <td>6701733</td>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>1406.200</td>\n",
              "      <td>3258.14</td>\n",
              "      <td>1850.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.53</td>\n",
              "      <td>1.761157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185540</th>\n",
              "      <td>12459146</td>\n",
              "      <td>12459146</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>415.150</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.853291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185541</th>\n",
              "      <td>12459147</td>\n",
              "      <td>12459147</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>375.050</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>4600.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.834741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185542</th>\n",
              "      <td>12459148</td>\n",
              "      <td>12459148</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>337.350</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>4700.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.816981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185543</th>\n",
              "      <td>12459149</td>\n",
              "      <td>12459149</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>302.650</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.799960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5185544</th>\n",
              "      <td>12459150</td>\n",
              "      <td>12459150</td>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>270.450</td>\n",
              "      <td>3839.81</td>\n",
              "      <td>4900.0</td>\n",
              "      <td>1085</td>\n",
              "      <td>4.22</td>\n",
              "      <td>0.783635</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5185545 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3621f79b-35b6-4d51-a138-d7d9dc272b90')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3621f79b-35b6-4d51-a138-d7d9dc272b90 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3621f79b-35b6-4d51-a138-d7d9dc272b90');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "google_colab = True\n",
        "\n",
        "if google_colab:\n",
        "    import tensorflow as tf\n",
        "    # Pring info\n",
        "    gpu_info = !nvidia-smi\n",
        "    gpu_info = '\\n'.join(gpu_info)\n",
        "    if gpu_info.find('failed') >= 0:\n",
        "        print('Not connected to a GPU')\n",
        "    else:\n",
        "        print(gpu_info)\n",
        "    \n",
        "    from psutil import virtual_memory\n",
        "    ram_gb = virtual_memory().total / 1e9\n",
        "    print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "    if ram_gb < 20:\n",
        "        print('Not using a high-RAM runtime')\n",
        "    else:\n",
        "        print('You are using a high-RAM runtime!')\n",
        "\n",
        "    # Code to read csv file into Colaboratory:\n",
        "    !pip install -U -q PyDrive\n",
        "    from pydrive.auth import GoogleAuth\n",
        "    from pydrive.drive import GoogleDrive\n",
        "    from google.colab import auth\n",
        "    from oauth2client.client import GoogleCredentials\n",
        "    # Authenticate and create the PyDrive client.\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    id = \"16SwdE7VcT6UCzVNQmtOM3914nwWJMOmN\"\n",
        "    downloaded = drive.CreateFile({'id':id}) \n",
        "    downloaded.GetContentFile('2020_2022_moneyness_filtere.csv')  \n",
        "    df_read = pd.read_csv('2020_2022_moneyness_filtere.csv')\n",
        "else:\n",
        "    file = \"../data/processed_data/2020_2022_moneyness_filtere.csv\"\n",
        "    df_read = pd.read_csv(file)\n",
        "\n",
        "display(df_read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CpcmhVq6Tnkm"
      },
      "outputs": [],
      "source": [
        "df = df_read\n",
        "del df_read\n",
        "\n",
        "# Group the data by Quote Date and calculate the mean for Underlying Price\n",
        "df_agg = df.groupby('Quote_date').mean().reset_index()\n",
        "\n",
        "# Values to returns\n",
        "df_agg[\"Underlying_return\"] = df_agg[\"Underlying_last\"].pct_change()\n",
        "\n",
        "lags = 10\n",
        "\n",
        "# Add the Underlying Price Lag column\n",
        "for i in range(1, lags + 1):\n",
        "    df_agg['Underlying_' + str(i)] = df_agg['Underlying_return'].shift(i)\n",
        "\n",
        "df = pd.merge(df, df_agg[['Quote_date', \"Underlying_return\"] + ['Underlying_' + str(i) for i in range(1, lags + 1)]], on='Quote_date', how='left')\n",
        "\n",
        "# Filter df between 2021-01-01 and 2022-12-31\n",
        "df = df[(df[\"Quote_date\"] >= \"2021-01-01\") & (df[\"Quote_date\"] <= \"2022-12-31\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1fuXIvmTnkn"
      },
      "source": [
        "### Format input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKAFyCmTTnko",
        "outputId": "925d49ae-4003-4388-ba61-19423bc62492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (1655728, 10, 1), (1655728, 4)\n",
            "Val shape: (184525, 10, 1), (184525, 4)\n",
            "Test shape: (165072, 10, 1), (165072, 4)\n"
          ]
        }
      ],
      "source": [
        "# Format settings\n",
        "max_timesteps = lags\n",
        "moneyness = False\n",
        "bs_vars = ['Moneyness', 'TTM', 'R'] if moneyness else ['Underlying_last', 'Strike', 'TTM', 'R']\n",
        "underlying_lags = ['Underlying_last'] + [f'Underlying_{i}' for i in range (1, max_timesteps)]\n",
        "\n",
        "def create_rw_dataset(window_number = 0, df = df):\n",
        "    '''Creates dataset for a single rolling window period offsett by the window number'''\n",
        "\n",
        "    # Create train, validation and test set split points\n",
        "    train_start = datetime(2021,1,1) + relativedelta(months=window_number)\n",
        "    val_start = train_start + relativedelta(months=11)\n",
        "    test_start = val_start + relativedelta(months=1)\n",
        "    test_end = test_start + relativedelta(months=1)\n",
        "    train_start = str(train_start.date())\n",
        "    val_start = str(val_start.date())\n",
        "    test_start = str(test_start.date())\n",
        "    test_end = str(test_end.date())\n",
        "\n",
        "    # Split train and validation data\n",
        "    df_train = df[(df['Quote_date'] >= train_start) & (df['Quote_date'] < val_start)]\n",
        "    df_val = df[(df['Quote_date'] >= val_start) & (df['Quote_date'] < test_start)]\n",
        "    df_test = df[(df['Quote_date'] >= test_start) & (df['Quote_date'] < test_end)]\n",
        "\n",
        "    del df\n",
        "    # Extract target values\n",
        "    train_y = (df_train['Price'] / df_train['Strike']).to_numpy() if moneyness else df_train['Price'].to_numpy()\n",
        "    val_y = (df_val['Price'] / df_val['Strike']).to_numpy() if moneyness else df_val['Price'].to_numpy()\n",
        "    test_y = (df_test['Price'] / df_test['Strike']).to_numpy() if moneyness else df_test['Price'].to_numpy()\n",
        "\n",
        "    # If usining moneyness, extract strike\n",
        "    if moneyness:\n",
        "        train_strike = df_train['Strike'].to_numpy()\n",
        "        val_strike = df_val['Strike'].to_numpy()\n",
        "        test_strike = df_test['Strike'].to_numpy()\n",
        "\n",
        "    # Convert dataframes to numpy arrays\n",
        "    train_x = [df_train[underlying_lags].to_numpy(), df_train[bs_vars].to_numpy()]\n",
        "    val_x = [df_val[underlying_lags].to_numpy(), df_val[bs_vars].to_numpy()]\n",
        "    test_x = [df_test[underlying_lags].to_numpy(), df_test[bs_vars].to_numpy()]\n",
        "\n",
        "    del df_train\n",
        "    del df_val\n",
        "\n",
        "    # Scale features based on training set\n",
        "    underlying_scaler = MinMaxScaler()\n",
        "    train_x[0] = underlying_scaler.fit_transform(train_x[0])\n",
        "    val_x[0] = underlying_scaler.transform(val_x[0])\n",
        "    test_x[0] = underlying_scaler.transform(test_x[0])\n",
        "\n",
        "    bs_scaler = MinMaxScaler()\n",
        "    train_x[1] = bs_scaler.fit_transform(train_x[1])\n",
        "    val_x[1] = bs_scaler.transform(val_x[1])\n",
        "    test_x[1] = bs_scaler.transform(test_x[1])\n",
        "\n",
        "\n",
        "    # Shuffle training set\n",
        "    np.random.seed(0)\n",
        "    shuffle = np.random.permutation(len(train_x[0]))\n",
        "    train_x = [train_x[0][shuffle], train_x[1][shuffle]]\n",
        "    train_y = train_y[shuffle]\n",
        "    if moneyness:\n",
        "        train_strike = train_strike[shuffle]\n",
        "\n",
        "    # Reshape data to fit LSTM\n",
        "    train_x = [train_x[0].reshape(len(train_x[0]), max_timesteps, 1), train_x[1]]\n",
        "    val_x = [val_x[0].reshape(len(val_x[0]), max_timesteps, 1), val_x[1]]\n",
        "    test_x = [test_x[0].reshape(len(test_x[0]), max_timesteps, 1), test_x[1]]\n",
        "\n",
        "    print(f'Train shape: {train_x[0].shape}, {train_x[1].shape}')\n",
        "    print(f'Val shape: {val_x[0].shape}, {val_x[1].shape}')\n",
        "    print(f'Test shape: {test_x[0].shape}, {test_x[1].shape}')\n",
        "\n",
        "    if moneyness:\n",
        "        return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike,\n",
        "    return train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test\n",
        "\n",
        "# Create the dataset for the first rolling window period\n",
        "if moneyness:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike = create_rw_dataset()\n",
        "else:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inutSrd8Tnko"
      },
      "source": [
        "# Model construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gewRG-rHTnkp"
      },
      "outputs": [],
      "source": [
        "def create_model(config):\n",
        "    '''Builds an LSTM-MLP model of minimum 2 layers sequentially from a given config dictionary'''\n",
        "\n",
        "    # Input layers\n",
        "    underlying_history = Input((config.LSTM_timesteps,1))\n",
        "    bs_vars = Input((config.Num_features,))\n",
        "\n",
        "    # LSTM layers\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(\n",
        "        units = config.LSTM_units,\n",
        "        activation = tanh,\n",
        "        input_shape = (config.LSTM_timesteps, 1),\n",
        "        return_sequences = True\n",
        "    ))\n",
        "\n",
        "    for _ in range(config.LSTM_layers - 2):\n",
        "        model.add(LSTM(\n",
        "            units = config.LSTM_units,\n",
        "            activation = tanh,\n",
        "            return_sequences = True\n",
        "        ))\n",
        "    \n",
        "    model.add(LSTM(\n",
        "        units = config.Interface_units,\n",
        "        activation = tanh,\n",
        "        return_sequences = False\n",
        "    ))\n",
        "\n",
        "    # MLP layers\n",
        "    layers = Concatenate()([model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), model(underlying_history), bs_vars])\n",
        "    \n",
        "    for _ in range(config.MLP_layers - 1):\n",
        "        layers = Dense(config.MLP_units)(layers)\n",
        "        layers = BatchNormalization(momentum=config.Bn_momentum)(layers)\n",
        "        layers = LeakyReLU()(layers)\n",
        "\n",
        "    output = Dense(1, activation='relu')(layers)\n",
        "\n",
        "    # Exponential decaying learning rate\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate = config.Lr,\n",
        "        decay_steps = int(len(train_x[0])/config.Minibatch_size),\n",
        "        decay_rate=config.Lr_decay\n",
        "    )\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=[underlying_history, bs_vars], outputs=output)\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=lr_schedule))\n",
        "\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqno7WFBTnkp"
      },
      "source": [
        "# Hyperparameter search setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__KmrL9HTnkp",
        "outputId": "3d318d3f-1fdb-4407-8888-692fe3d19449"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Lr uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 2. Lr_decay uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: k8ofgax7\n",
            "Sweep URL: https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing/sweeps/k8ofgax7\n"
          ]
        }
      ],
      "source": [
        "# Configuring the sweep hyperparameter search space\n",
        "sweep_configuration = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'LSTM-MLP v5.0',\n",
        "    'metric': {\n",
        "        'goal': 'minimize', \n",
        "        'name': 'val_loss'\n",
        "\t\t},\n",
        "    'parameters': {\n",
        "        'LSTM_units': {\n",
        "            'values': [4, 8, 16, 32]},\n",
        "        'Interface_units': {\n",
        "            'values': [4, 8, 16, 32]},\n",
        "        'MLP_units': {\n",
        "            'values': [50, 200, 600]},\n",
        "        'LSTM_timesteps': {\n",
        "            'values': [10, 20, 40]},\n",
        "        'LSTM_layers': {\n",
        "            'distribution': 'int_uniform',\n",
        "            'max': 8, 'min': 2},\n",
        "        'MLP_layers': {\n",
        "            'distribution': 'int_uniform',\n",
        "            'max': 8, 'min': 2},\n",
        "        'Bn_momentum': {\n",
        "            'values': [0.1, 0.4, 0.7, 0.99]},\n",
        "        'Lr': {\n",
        "            'distribution': 'log_uniform',\n",
        "            'max': log(0.1), 'min': log(0.0001)},\n",
        "        'Lr_decay': {\n",
        "            'distribution': 'log_uniform',\n",
        "            'max': log(1), 'min': log(0.8)},        \n",
        "        'Minibatch_size': {\n",
        "            'value': 4096},\n",
        "        'Min_delta': {\n",
        "            'value': 0.01 if moneyness else 1},\n",
        "        'Patience': {\n",
        "            'value': 20},\n",
        "        'Num_features': {\n",
        "            'value': 3 if moneyness else 4},\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize sweep and creating sweepID\n",
        "\n",
        "# If new sweep, uncomment the line below and comment the line after it\n",
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project='Deep learning for option pricing') \n",
        "#sweep_id = '98bxt6oq'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AogdJkrRTnkq"
      },
      "source": [
        "# Run hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "67l6iqWdTnkq"
      },
      "outputs": [],
      "source": [
        "#WIP\n",
        "class MSE_LossCallback(Callback):\n",
        "    def __init__(self, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
        "        self.train_x = train_x\n",
        "        self.train_y = train_y\n",
        "        self.train_strike = train_strike\n",
        "        self.val_x = val_x\n",
        "        self.val_y = val_y\n",
        "        self.val_strike = val_strike\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        train_pred = self.model(train_x)\n",
        "        val_pred = self.model(val_x)\n",
        "\n",
        "        train_mse = reduce_mean(square(multiply(train_pred[:,0] - self.train_y, self.train_strike)))\n",
        "        val_mse = reduce_mean(square(multiply(val_pred[:,0] - self.val_y, self.val_strike)))\n",
        "\n",
        "        print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5ogZE0y_Tnkq"
      },
      "outputs": [],
      "source": [
        "# Calculate the training and validation MSE loss on the actual option price when using price/strike as the target\n",
        "def MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike):\n",
        "    train_pred = model(train_x)\n",
        "    val_pred = model(val_x)\n",
        "\n",
        "    train_mse = reduce_mean(square((train_pred[:,0] - train_y)*train_strike))\n",
        "    val_mse = reduce_mean(square((val_pred[:,0] - val_y)*val_strike))\n",
        "\n",
        "    print(f' Training scaled MSE: {train_mse}, Validation scaled MSE: {val_mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xf-ICRDKTnkr"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "from tensorflow.keras import backend as k\n",
        "\n",
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        k.clear_session()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4CRxFJrTnkr"
      },
      "source": [
        "## Creating trainer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EZsaCBmrTnkr"
      },
      "outputs": [],
      "source": [
        "def trainer(train_x = train_x, train_y = train_y, val_x = val_x, val_y = val_y, config = None, project = None, checkpoint_path = None):\n",
        "    # Initialize a new wandb run\n",
        "    with wandb.init(config=config, project = project):\n",
        "\n",
        "        # If called by wandb.agent, as below,\n",
        "        # this config will be set by Sweep Controller\n",
        "        config = wandb.config\n",
        "\n",
        "        # Build model and create callbacks\n",
        "        model = create_model(config)\n",
        "\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            min_delta = config.Min_delta,\n",
        "            patience = config.Patience,\n",
        "        )\n",
        "        \n",
        "        wandb_callback = WandbCallback(\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            save_model=False\n",
        "        )\n",
        "\n",
        "        # Checkpoints\n",
        "        \n",
        "        # Check if the checkpoint folder exists\n",
        "        if checkpoint_path and not os.path.exists(checkpoint_path):\n",
        "            # Create the checkpoint folder if it does not exist\n",
        "            os.makedirs(checkpoint_path)\n",
        "        \n",
        "        checkpoint = ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True\n",
        "        )\n",
        "\n",
        "        # Adapt sequence length to config\n",
        "        train_x_adjusted = [train_x[0][:, :config.LSTM_timesteps, :], train_x[1]]\n",
        "        val_x_adjusted = [val_x[0][:, :config.LSTM_timesteps, :], val_x[1]]\n",
        "        print(f'Train shape: {train_x_adjusted[0].shape}, {train_x_adjusted[0].shape}')\n",
        "        print(f'Val shape: {val_x_adjusted[0].shape}, {val_x_adjusted[0].shape}')\n",
        "\n",
        "        # Train model\n",
        "        model.fit(\n",
        "            train_x_adjusted,\n",
        "            train_y,\n",
        "            batch_size = config.Minibatch_size,\n",
        "            validation_data = (val_x_adjusted, val_y),\n",
        "            epochs = 1000,\n",
        "            callbacks = [early_stopping, wandb_callback, checkpoint, ClearMemory()] if checkpoint_path else [early_stopping, wandb_callback, ClearMemory()],\n",
        "        )\n",
        "\n",
        "        if moneyness:\n",
        "            MSE_loss(model, train_x, train_y, train_strike, val_x, val_y, val_strike)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQyg6eZKTnkr"
      },
      "source": [
        "### Run full sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mC5YLKBTTnks"
      },
      "outputs": [],
      "source": [
        "#wandb.agent(sweep_id=sweep_id, function=trainer, project='Deep learning for option pricing - test area', count = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuuoYP4ITnks"
      },
      "source": [
        "### Single run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaS4BiSNTnks"
      },
      "source": [
        "# Rolling window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ifDAjXS3Tnks"
      },
      "outputs": [],
      "source": [
        "def calculate_error(predictions, original):\n",
        "    m = MeanSquaredError()\n",
        "    m.update_state(predictions, original)\n",
        "    print(\"MSE:\", m.result().numpy())\n",
        "    m = RootMeanSquaredError()\n",
        "    m.update_state(predictions, original)\n",
        "    print(\"RMSE:\", m.result().numpy())\n",
        "\n",
        "class config_object:\n",
        "    def __init__(self, config):\n",
        "        self.LSTM_units = config['LSTM_units']\n",
        "        self.Interface_units = config['Interface_units']\n",
        "        self.MLP_units = config['MLP_units']\n",
        "        self.LSTM_timesteps = config['LSTM_timesteps']\n",
        "        self.LSTM_layers = config['LSTM_layers']\n",
        "        self.MLP_layers = config['MLP_layers']\n",
        "        self.Bn_momentum = config['Bn_momentum']\n",
        "        self.Lr = config['Lr']\n",
        "        self.Lr_decay = config['Lr_decay']\n",
        "        self.Minibatch_size = config['Minibatch_size']\n",
        "        self.Min_delta = config['Min_delta']\n",
        "        self.Patience = config['Patience']\n",
        "        self.Num_features = config['Num_features']\n",
        "        self.Architecture = config['Architecture']\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lRV8wlklTnks",
        "outputId": "d3886a5e-ada1-41fd-84eb-3e71dd4cb296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Train shape: (1655728, 10, 1), (1655728, 4)\n",
            "Val shape: (184525, 10, 1), (184525, 4)\n",
            "Test shape: (165072, 10, 1), (165072, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230324_202438-gh7paipe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/gh7paipe' target=\"_blank\">cool-dream-103</a></strong> to <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/gh7paipe' target=\"_blank\">https://wandb.ai/avogadro/Deep%20learning%20for%20option%20pricing%20-%20rolling%20windows/runs/gh7paipe</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 10, 1)]      0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 32)           4832        ['input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]',                \n",
            "                                                                  'input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 164)          0           ['sequential[0][0]',             \n",
            "                                                                  'sequential[1][0]',             \n",
            "                                                                  'sequential[2][0]',             \n",
            "                                                                  'sequential[3][0]',             \n",
            "                                                                  'sequential[4][0]',             \n",
            "                                                                  'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 600)          99000       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 600)         2400        ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 600)          0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 600)          360600      ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 600)         2400        ['dense_1[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 600)          0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 600)          360600      ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 600)         2400        ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 600)          0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          360600      ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 600)         2400        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 600)          0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 600)          360600      ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 600)         2400        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 600)          0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 600)          360600      ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 600)         2400        ['dense_5[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 600)          0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 1)            601         ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,921,833\n",
            "Trainable params: 1,914,633\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n",
            "Train shape: (1655728, 10, 1), (1655728, 10, 1)\n",
            "Val shape: (184525, 10, 1), (184525, 10, 1)\n",
            "Epoch 1/1000\n",
            "405/405 [==============================] - 38s 51ms/step - loss: 464341.5625 - val_loss: 526328.5000\n",
            "Epoch 2/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 159055.3438 - val_loss: 129251.5938\n",
            "Epoch 3/1000\n",
            "405/405 [==============================] - 21s 46ms/step - loss: 28885.5938 - val_loss: 4647.4619\n",
            "Epoch 4/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 4013.6064 - val_loss: 1930.3213\n",
            "Epoch 5/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 856.6140 - val_loss: 3349.6252\n",
            "Epoch 6/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 415.3686 - val_loss: 2795.8220\n",
            "Epoch 7/1000\n",
            "405/405 [==============================] - 21s 46ms/step - loss: 300.9276 - val_loss: 1627.6859\n",
            "Epoch 8/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 263.3923 - val_loss: 6537.4756\n",
            "Epoch 9/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 267.0217 - val_loss: 2389.2861\n",
            "Epoch 10/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 240.5522 - val_loss: 6882.5757\n",
            "Epoch 11/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 202.3076 - val_loss: 263.7152\n",
            "Epoch 12/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 208.5430 - val_loss: 197.3950\n",
            "Epoch 13/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 204.3217 - val_loss: 383.6243\n",
            "Epoch 14/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 202.6664 - val_loss: 2541.4678\n",
            "Epoch 15/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 196.4998 - val_loss: 275.3842\n",
            "Epoch 16/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 187.7400 - val_loss: 544.9588\n",
            "Epoch 17/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 191.0546 - val_loss: 176.9779\n",
            "Epoch 18/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 196.9096 - val_loss: 109.1023\n",
            "Epoch 19/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 184.7657 - val_loss: 208.0162\n",
            "Epoch 20/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 185.2743 - val_loss: 593.8789\n",
            "Epoch 21/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 181.2775 - val_loss: 390.7284\n",
            "Epoch 22/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 194.6714 - val_loss: 94.5096\n",
            "Epoch 23/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 182.8901 - val_loss: 112.1929\n",
            "Epoch 24/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 176.6036 - val_loss: 99.4364\n",
            "Epoch 25/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 173.0964 - val_loss: 142.2446\n",
            "Epoch 26/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 175.5375 - val_loss: 132.7740\n",
            "Epoch 27/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 186.1402 - val_loss: 118.9623\n",
            "Epoch 28/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 175.6860 - val_loss: 136.4914\n",
            "Epoch 29/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 176.3957 - val_loss: 129.7170\n",
            "Epoch 30/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 170.8197 - val_loss: 133.7759\n",
            "Epoch 31/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 177.8914 - val_loss: 112.8396\n",
            "Epoch 32/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 186.3358 - val_loss: 109.3440\n",
            "Epoch 33/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 180.8743 - val_loss: 109.6881\n",
            "Epoch 34/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 183.5121 - val_loss: 112.0274\n",
            "Epoch 35/1000\n",
            "405/405 [==============================] - 20s 45ms/step - loss: 175.8396 - val_loss: 117.7544\n",
            "Epoch 36/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 163.1018 - val_loss: 121.6360\n",
            "Epoch 37/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 183.1698 - val_loss: 108.9769\n",
            "Epoch 38/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 182.0499 - val_loss: 113.5822\n",
            "Epoch 39/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 167.6883 - val_loss: 109.2610\n",
            "Epoch 40/1000\n",
            "405/405 [==============================] - 21s 45ms/step - loss: 177.0344 - val_loss: 115.3486\n",
            "Epoch 41/1000\n",
            "110/405 [=======>......................] - ETA: 12s - loss: 170.7421"
          ]
        }
      ],
      "source": [
        "num_windows = 12\n",
        "\n",
        "# Update to v.5.0\n",
        "config = {\n",
        "    'LSTM_units': 4,\n",
        "    'Interface_units': 32,\n",
        "    'MLP_units': 600,\n",
        "    'LSTM_timesteps': 10,\n",
        "    'LSTM_layers': 2,\n",
        "    'MLP_layers': 7,\n",
        "    'Bn_momentum': 0.99,\n",
        "    'Lr': 0.0010401686452862443,\n",
        "    'Lr_decay': 0.800108103409341,\n",
        "    'Minibatch_size': 4096,\n",
        "    'Min_delta': 0.01 if moneyness else 1,\n",
        "    'Patience': 20,\n",
        "    'Num_features': 3 if moneyness else 4,\n",
        "    'Architecture': 'LSTM-MLP v.5.0',\n",
        "}\n",
        "\n",
        "# Ask before training, so that you don't have to verify later\n",
        "if google_colab == True:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "df_test_combined = pd.DataFrame()\n",
        "\n",
        "checkpoint_time = datetime.now().strftime(\"%m-%d_%H-%M\")\n",
        "\n",
        "for window in range(num_windows):\n",
        "    if moneyness:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
        "    else:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
        "\n",
        "    checkpoint_path = f'./checkpoint/{checkpoint_time}/{train_start}/'\n",
        "\n",
        "    config['Dataset'] = f'{train_start} - {val_start} - {test_start}'\n",
        "\n",
        "    trainer(config = config, project = 'Deep learning for option pricing - rolling windows', checkpoint_path = checkpoint_path)\n",
        "    co = config_object(config)\n",
        "    c_model = create_model(co)\n",
        "    c_model.load_weights(checkpoint_path)\n",
        "    predictions = np.array(c_model(test_x))\n",
        "    print(f'--- Predictions for test_start {test_start} ---')\n",
        "    calculate_error(predictions, test_y)\n",
        "    print('-------------------------------------------')\n",
        "    df_test[\"Prediction\"] = predictions\n",
        "    df_test_combined = pd.concat([df_test_combined, df_test[[\"Quote_date\", \"Price\", \"Prediction\"] + bs_vars]])\n",
        "\n",
        "\n",
        "print(f\"--- All model predictions ---\")\n",
        "calculate_error(df_test_combined[\"Prediction\"], df_test_combined[\"Price\"])\n",
        "print(\"-------------------------------------------\")\n",
        "\n",
        "if google_colab == False:\n",
        "    predictions_path = './predictions/'\n",
        "    if checkpoint_path and not os.path.exists(predictions_path):\n",
        "        os.makedirs(predictions_path)\n",
        "    df_test_combined.to_csv(f'{predictions_path}{datetime.now().strftime(\"%m-%d_%H-%M\")}.csv')\n",
        "\n",
        "if google_colab == True:\n",
        "    from google.colab import drive\n",
        "    path = '/content/drive/My Drive/Predictions/predictions2022v.5.0.csv'\n",
        "    with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "        df_test_combined.to_csv(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucgo2McGTnkt"
      },
      "source": [
        "### Load single model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YggplbxMTnkt"
      },
      "outputs": [],
      "source": [
        "# Update to v.5.0\n",
        "config = {\n",
        "    'LSTM_units': 4,\n",
        "    'Interface_units': 32,\n",
        "    'MLP_units': 600,\n",
        "    'LSTM_timesteps': 10,\n",
        "    'LSTM_layers': 2,\n",
        "    'MLP_layers': 7,\n",
        "    'Bn_momentum': 0.99,\n",
        "    'Lr': 0.0010401686452862443,\n",
        "    'Lr_decay': 0.800108103409341,\n",
        "    'Minibatch_size': 4096,\n",
        "    'Min_delta': 0.01 if moneyness else 1,\n",
        "    'Patience': 20,\n",
        "    'Num_features': 3 if moneyness else 4,\n",
        "    'Architecture': 'LSTM-MLP v.5.0',\n",
        "}\n",
        "\n",
        "window = 1\n",
        "if moneyness:\n",
        "        train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test, train_strike, val_strike, test_strike, = create_rw_dataset(window)\n",
        "else:\n",
        "    train_x, train_y, val_x, val_y, test_x, test_y, train_start, val_start, test_start, df_test = create_rw_dataset(window)\n",
        "\n",
        "checkpoint_path = f'./checkpoint/03-20_12-35/{train_start}/'\n",
        "\n",
        "co = config_object(config)\n",
        "c_model = create_model(co)\n",
        "c_model.load_weights(checkpoint_path)\n",
        "predictions = np.array(c_model(test_x))\n",
        "print(f'--- Predictions for {test_start} ---')\n",
        "calculate_error(predictions, test_y)\n",
        "print('-------------------------------------------')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}